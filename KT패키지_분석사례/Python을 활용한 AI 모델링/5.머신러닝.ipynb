{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습-퀴즈] Python을 활용한 AI 모델링 - 머신러닝 파트\n",
    "+ 이번시간에는 Python을 활용한 AI 모델링에서 머신러닝에 대해 실습해 보겠습니다.\n",
    "+ 머신러닝 모델에는 아래와 같이 모델들이 있습니다.\n",
    " + 단일 분류예측 모델 : LogisticRegression, KNN, DecisionTree\n",
    " + 앙상블(Ensemble) 모델 : RandomForest, XGBoost, LGBM, Stacking, Weighted Blending\n",
    "+ 솔직히, 머신러닝이 딥러닝보다 코딩하기 쉽습니다. 4줄 템플릿에 맞쳐 코딩하면 되기 때문입니다.\n",
    "+ 한가지 당부 드리고 싶은 말은 \"백문이불여일타\" 입니다. \n",
    "+ 이론보다 실습이 더 많은 시간과 노력이 투자 되어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습목차\n",
    "1. 실습준비\n",
    "2. 머신러닝 모델 프로세스\n",
    " - 데이터 가져오기\n",
    " - 데이터 전처리\n",
    " - Train, Test 데이터셋 분할\n",
    " - 데이터 정규화\n",
    " - 단일 분류예측 모델 : LogisticRegression, KNN, DecisionTree\n",
    " - 앙상블(Ensemble) 모델 : RandomForest, XGBoost, LGBM, Stacking, Weighted Blending\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnqYDATsRdyk"
   },
   "source": [
    "# \n",
    "# 1. 실습준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드실행시 경고 메시지 무시\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "# 2. 머신러닝 모델 프로세스\n",
    "① 라이브러리 임포트(import)  \n",
    "② 데이터 가져오기(Loading the data)  \n",
    "③ 탐색적 데이터 분석(Exploratory Data Analysis)  \n",
    "④ 데이터 전처리(Data PreProcessing) : 데이터타입 변환, Null 데이터 처리, 누락데이터 처리, \n",
    "더미특성 생성, 특성 추출 (feature engineering) 등  \n",
    "⑤ Train, Test  데이터셋 분할  \n",
    "⑥ 데이터 정규화(Normalizing the Data)  \n",
    "⑦ 모델 개발(Creating the Model)  \n",
    "⑧ 모델 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ① 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 필요 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ② 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cust_data.csv 파일 컬럼명\n",
    "+ 고객등급(class), 성별(sex), 나이(age), 사용서비스수(service), 서비스중지여부 (stop), 미납여부(npay)\n",
    "+ 3개월 평균 요금(avg_bill), A서비스 3개월 평균요금(A_bill), B서비스 3개월 평균요금(B_bill), 해지여부(termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞쪽 전처리에서 저장한 cust_data.csv 파일 읽기\n",
    "df = pd.read_csv('cust_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ③ 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10컬럼, 9930 라인\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination 레이블 불균형 \n",
    "df['termination'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ④ 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Object 컬럼에 대해 Pandas get_dummies 함수 활용하여 One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object 컬럼 리스트 정의\n",
    "cal_cols = ['class', 'sex', 'stop', 'npay', 'termination', 'bill_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas get_dummies 함수 사용하여 Object 컬럼에 대해 One-Hot-Encoding 수행\n",
    "df1 = pd.get_dummies(data=df, columns=cal_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19컬럼, 7814 라인\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⑤ Train, Test  데이터셋 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력(X)과 레이블(y) 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> **[문제] df1 DataFrame에서 'termination_Y' 컬럼을 제외한 나머지 정보를 X에 저장하세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame drop 함수 활용\n",
    "# 'termination_Y' 컬럼 삭제\n",
    "# DataFrame에서 values만 X에 저장\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> **[문제] df1 DataFrame에서 'termination_Y' 컬럼의 값을 y로 저장하세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 'termination_Y' 컬럼 사용\n",
    "# DataFrame에서 values만 y에 저장\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train , Test dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> **[문제] Train dataset, Test dataset 나누세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset, Test dataset 나누기 : train_test_split 함수 사용\n",
    "# 입력 : X, y \n",
    "# Train : Test 비율 = 7: 3  --> test_size=0.3\n",
    "# y Class 비율에 맞게 나주어 주세요 : stratify=y\n",
    "# 여러번 수행해도 같은 결과 나오게 고정하기 : random_state=42 \n",
    "# 결과 : X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⑥ 데이터 정규화/스케일링(Normalizing/Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 분포 이루어진 컬럼 확인\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> **[문제] MinMaxScaler 함수를 'scaler'로 정의 하세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이키런의 MinMaxScaler() 함수 활용\n",
    "# 정의할 결과를 'scaler'로 매핑\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:2], y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 모델 입력갯수, 출력갯수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⑦ 모델 개발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt9pqvyOGW0N"
   },
   "source": [
    "#### 모델별 바차트 그려주고 성능 확인을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwA1iqfDGWkw",
    "outputId": "22dc39f7-9d25-4190-88e1-29a4d28635d4"
   },
   "outputs": [],
   "source": [
    "# 모델별로 Accuracy 점수 저장\n",
    "# 모델 Accuracy 점수 순서대로 바차트를 그려 모델별로 성능 확인 가능\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "my_predictions = {}\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
    "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
    "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
    "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
    "         ]\n",
    "\n",
    "# 모델명, 예측값, 실제값을 주면 위의 plot_predictions 함수 호출하여 Scatter 그래프 그리며\n",
    "# 모델별 MSE값을 Bar chart로 그려줌\n",
    "def accuracy_eval(name_, pred, actual):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    plt.figure(figsize=(12, 9))\n",
    "\n",
    "    acc = accuracy_score(actual, pred)\n",
    "    my_predictions[name_] = acc * 100\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'accuracy'])\n",
    "    print(df)\n",
    "   \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['accuracy'])\n",
    "    \n",
    "    for i, v in enumerate(df['accuracy']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('accuracy', fontsize=18)\n",
    "    plt.xlim(0, 100)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "### 1) 로지스틱 회귀 (LogisticRegression, 분류)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> **[문제] LogisticRegression 모델 정의하고 학습시키세요.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression 함수 사용 및 정의 : lg 저장\n",
    "# 정의된 LogisticRegression 학습 fit() : 입력값으로 X_train, y_train 준다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기 성능 평가(score)\n",
    "lg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류기 성능 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_pred = lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차행렬\n",
    "# TN  FP\n",
    "# FN  TP\n",
    "\n",
    "confusion_matrix(y_test, lg_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 : 굉장히 높다\n",
    "accuracy_score(y_test, lg_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도\n",
    "precision_score(y_test, lg_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현율 : 굉장히 낮다.\n",
    "recall_score(y_test, lg_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정밀도 + 재현율\n",
    "f1_score(y_test, lg_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, lg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval('LogisticRegression', lg_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   \n",
    "### 2) KNN (K-Nearest Neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval('K-Nearest Neighbor', knn_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "### 3) 결정트리(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color=blue> **[문제] 학습된 DecisionTreeClassifier 모델로 예측해 보기** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 학습 모델 : dt\n",
    "# DecisionTreeClassifier 모델의 predict() 활용 : 입력값으로 X_test\n",
    "# 결과 : dt_pred 저장\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_eval('DecisionTree', dt_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y_f-BWX6CCA"
   },
   "source": [
    "### \n",
    "### **앙상블 기법의 종류**\n",
    "- 배깅 (Bagging): 여러개의 DecisionTree 활용하고 샘플 중복 생성을 통해 결과 도출. RandomForest\n",
    "- 부스팅 (Boosting): 약한 학습기를 순차적으로 학습을 하되, 이전 학습에 대하여 잘못 예측된 데이터에 가중치를 부여해 오차를 보완해 나가는 방식. XGBoost, LGBM\n",
    "- 스태킹 (Stacking): 여러 모델을 기반으로 예측된 결과를 통해 Final 학습기(meta 모델)이 다시 한번 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![앙상블](https://teddylee777.github.io/images/2019-12-18/image-20191217144823555.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "### 4) 랜덤포레스트(RandomForest)\n",
    "+ Bagging 대표적인 모델로써, 훈련셋트를 무작위로 각기 다른 서브셋으로 데이터셋을 만들고\n",
    "+ 여러개의 DecisonTree로 학습하고 다수결로 결정하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpOEkIoCAdFd"
   },
   "source": [
    "**주요 Hyperparameter**\n",
    "- random_state: 랜덤 시드 고정 값. 고정해두고 튜닝할 것!\n",
    "- n_jobs: CPU 사용 갯수\n",
    "- max_depth: 깊어질 수 있는 최대 깊이. 과대적합 방지용\n",
    "- n_estimators: 앙상블하는 트리의 갯수\n",
    "- max_features: 최대로 사용할 feature의 갯수. 과대적합 방지용\n",
    "- min_samples_split: 트리가 분할할 때 최소 샘플의 갯수. default=2. 과대적합 방지용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=3, random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yd3AA9mFa_0n"
   },
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-RkzXSShS6ks",
    "outputId": "eaec818c-5fc2-4b39-fecf-5b1b2895ccad"
   },
   "outputs": [],
   "source": [
    "accuracy_eval('RandomForest Ensemble', rfc_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "### 5) XGBoost\n",
    "+ 여러개의 DecisionTree를 결합하여 Strong Learner 만드는 Boosting 앙상블 기법\n",
    "+ Kaggle 대회에서 자주 사용하는 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw17wJya85Ms"
   },
   "source": [
    "**주요 특징**\n",
    "- scikit-learn 패키지가 아닙니다.\n",
    "- 성능이 우수함\n",
    "- GBM보다는 빠르고 성능도 향상되었습니다.\n",
    "- 여전히 학습시간이 매우 느리다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fAjfIX9Jpcx"
   },
   "source": [
    "**주요 Hyperparameter**\n",
    "- random_state: 랜덤 시드 고정 값. 고정해두고 튜닝할 것!\n",
    "- n_jobs: CPU 사용 갯수\n",
    "- learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1\n",
    "- n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100\n",
    "- max_depth: 트리의 깊이. 과대적합 방지용. default=3. \n",
    "- subsample: 샘플 사용 비율. 과대적합 방지용. default=1.0\n",
    "- max_features: 최대로 사용할 feature의 비율. 과대적합 방지용. default=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=3, random_state=42)  \n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval('XGBoost', xgb_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "### 6) Light GBM\n",
    "+ XGBoost와 함께 주목받는 DecisionTree 알고리즘 기반의 Boosting 앙상블 기법\n",
    "+ XGBoost에 비해 학습시간이 짧은 편이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Unk2_LocLD_I"
   },
   "source": [
    "**주요 특징**\n",
    "- scikit-learn 패키지가 아닙니다.\n",
    "- 성능이 우수함\n",
    "- 속도도 매우 빠릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaKdEHJpLrm4"
   },
   "source": [
    "**주요 Hyperparameter**\n",
    "- random_state: 랜덤 시드 고정 값. 고정해두고 튜닝할 것!\n",
    "- n_jobs: CPU 사용 갯수\n",
    "- learning_rate: 학습율. 너무 큰 학습율은 성능을 떨어뜨리고, 너무 작은 학습율은 학습이 느리다. 적절한 값을 찾아야함. n_estimators와 같이 튜닝. default=0.1\n",
    "- n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100\n",
    "- max_depth: 트리의 깊이. 과대적합 방지용. default=3. \n",
    "- colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(n_estimators=3, random_state=42)  \n",
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pred = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval('LGBM', lgbm_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCQyRaTsNYbX"
   },
   "source": [
    "#### \n",
    "### 7) Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-kKF3g9Qw95"
   },
   "source": [
    "개별 모델이 예측한 데이터를 기반으로 **final_estimator** 종합하여 예측을 수행합니다.\n",
    "- 성능을 극으로 끌어올릴 때 활용하기도 합니다.\n",
    "- 과대적합을 유발할 수 있습니다. (특히, 데이터셋이 적은 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DA0HqTLSK7fZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor, StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hW_QeDoyNViP"
   },
   "outputs": [],
   "source": [
    "stack_models = [\n",
    "    ('LogisticRegression', lg), \n",
    "    ('KNN', knn), \n",
    "    ('DecisionTree', dt),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFD0xCsyNN9M"
   },
   "outputs": [],
   "source": [
    "# stack_models로 선언된 모델(LogisticRegression,KNN,DecisionTree)의 예측결과를 최종 meta_model(final_estimator)을 RandomForest(rfc) 사용하여 분류 예측 \n",
    "stacking = StackingClassifier(stack_models, final_estimator=rfc, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking.fit(X_train, y_train)   # 1분 20초 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wGI-q5hcOome",
    "outputId": "ec24b407-fac8-4bd3-f092-0eafd142747f"
   },
   "outputs": [],
   "source": [
    "stacking_pred = stacking.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_eval('Stacking Ensemble', stacking_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X284iz5vRa7A"
   },
   "source": [
    "#### \n",
    "### 8) Weighted Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMB3W6tXRdl2"
   },
   "source": [
    "각 모델의 예측값에 대하여 weight를 곱하여 최종 output 계산\n",
    "- 모델에 대한 가중치를 조절하여, 최종 output을 산출합니다.\n",
    "- **가중치의 합은 1.0**이 되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6ayGpgWRhu1"
   },
   "outputs": [],
   "source": [
    "final_outputs = {\n",
    "    'DecisionTree': dt_pred, \n",
    "    'randomforest': rfc_pred, \n",
    "    'xgb': xgb_pred, \n",
    "    'lgbm': lgbm_pred,\n",
    "    'stacking': stacking_pred,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qinsFfubSHad"
   },
   "outputs": [],
   "source": [
    "final_prediction=\\\n",
    "final_outputs['DecisionTree'] * 0.1\\\n",
    "+final_outputs['randomforest'] * 0.2\\\n",
    "+final_outputs['xgb'] * 0.25\\\n",
    "+final_outputs['lgbm'] * 0.15\\\n",
    "+final_outputs['stacking'] * 0.3\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 계산값이 0.5 초과하면 1, 그렇지 않으면 0\n",
    "final_prediction = np.where(final_prediction > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_CcJWidqSHQI",
    "outputId": "d4eff17f-242e-4f85-d697-5860750693bc"
   },
   "outputs": [],
   "source": [
    "accuracy_eval('Weighted Blending', final_prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "## 배운 내용 정리\n",
    "1. 머신러닝 모델 프로세스 <br>\n",
    "① 라이브러리 임포트(import)  \n",
    "② 데이터 가져오기(Loading the data)  \n",
    "③ 탐색적 데이터 분석(Exploratory Data Analysis)  \n",
    "④ 데이터 전처리(Data PreProcessing) : 데이터타입 변환, Null 데이터 처리, 누락데이터 처리, \n",
    "더미특성 생성, 특성 추출 (feature engineering) 등  \n",
    "⑤ Train, Test  데이터셋 분할  \n",
    "⑥ 데이터 정규화(Normalizing the Data)  \n",
    "⑦ 모델 개발(Creating the Model)  \n",
    "⑧ 모델 성능 평가\n",
    "2. 평가 지표 활용 : 모델별 성능 확인을 위한 함수 (가져다 쓰면 된다)\n",
    "3. 단일 회귀예측 모델 : LogisticRegression, KNN, DecisionTree\n",
    "4. 앙상블 (Ensemble) : RandomForest, XGBoost, LGBM, Stacking, Weighted Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "003.앙상블(Ensemble)-Voting,Bagging,Boosting,Stacking.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}